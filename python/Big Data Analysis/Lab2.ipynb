{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d64e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Lab 2:  DATA VARIETY EXPLORATION\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Lab 2:  DATA VARIETY EXPLORATION\")\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca8303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"json\": \"employees.json\",\n",
    "    \"xml\": \"employees.xml\",\n",
    "    \"csv\": \"employees.csv\",\n",
    "    \"text\": \"bigdata_text.txt\"\n",
    "}\n",
    "\n",
    "def process_csv_data():\n",
    "    \"\"\"Process the structured data\"\"\"\n",
    "    print(\"PROCESSING CSV DATA (Structured)\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(file_paths[\"csv\"])\n",
    "\n",
    "    print(\"CSV Records Loaded: \")\n",
    "    print(\"\\nSample data: \")\n",
    "    print(df.head())\n",
    "    print(f\"\\nAverage Salary: {df['salary'].mean():.2f}\")\n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"Processing Time: {processing_time:.2f} seconds\")\n",
    "    return df, processing_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "795cdcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_data():\n",
    "    \"\"\"Process the semi-structured data\"\"\"\n",
    "    print(\"PROCESSING JSON DATA (Semi-Structured)\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with open(file_paths[\"json\"], \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for emp in data[\"employees\"]:\n",
    "        records.append(\n",
    "            {\n",
    "                \"name\": emp[\"name\"],\n",
    "                \"city\": emp[\"city\"],\n",
    "                \"salary\": emp[\"salary\"],\n",
    "                \"skill_count\": len(emp[\"skills\"])\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(\"JSON Records Loaded: \")\n",
    "    print(\"\\nSample data: \")\n",
    "    print(df.head())\n",
    "    print(f\"\\nAverage Salary: {df['salary'].mean():.2f}\")\n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"Processing Time: {processing_time:.2f} seconds\")\n",
    "    return df, processing_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a207d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_data():\n",
    "    \"\"\"Process the semi-structured data\"\"\"\n",
    "    print(\"PROCESSING XML DATA (Semi-Structured)\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with open(file_paths[\"xml\"], \"r\") as f:\n",
    "        data = ET.parse(f)\n",
    "    root = data.getroot()\n",
    "\n",
    "    records = []\n",
    "    for emp in root.findall(\"employee\"):\n",
    "        skills_elem = emp.find(\"skills\")\n",
    "        skill_count = len(skills_elem.findall(\"skill\")) if skills_elem is not None else 0\n",
    "        records.append(\n",
    "            {\n",
    "                \"name\": emp.find(\"name\").text,\n",
    "                \"city\": emp.find(\"city\").text,\n",
    "                \"salary\": float(emp.find(\"salary\").text),\n",
    "                \"skill_count\": skill_count\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(\"XML Records Loaded: \")\n",
    "    print(\"\\nSample data: \")\n",
    "    print(df.head())\n",
    "    print(f\"\\nAverage Salary: {df['salary'].mean():.2f}\")\n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"Processing Time: {processing_time:.2f} seconds\")\n",
    "    return df, processing_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea1776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_data():\n",
    "    \"\"\"Process the unstructured text data\"\"\"\n",
    "    print(\"PROCESSING TEXT DATA (Unstructured)\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with open(file_paths[\"text\"], \"r\") as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    words = text_content.lower().split()\n",
    "    words_count = len(words)\n",
    "    unique_words = len(set(words))\n",
    "    sentences = [s.strip() for s in text_content.split('.') if s.strip()]\n",
    "\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        clean_word = word.strip('.,\\n')\n",
    "        if len(clean_word) > 2:\n",
    "            word_freq[clean_word] = word_freq.get(clean_word, 0) + 1\n",
    "\n",
    "    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"Text Analysis Complete\")\n",
    "    print(f\"Total Words: {words_count}\")\n",
    "    print(f\"Unique Words: {unique_words}\")\n",
    "    print(f\"Total Sentences: {len(sentences)}\")\n",
    "    print(\"Top 5 Words:\")\n",
    "    for word, freq in top_words:\n",
    "        print(f\"  {word}: {freq}\")\n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"Processing Time: {processing_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2983c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING CSV DATA (Structured)\n",
      "----------------------------------------\n",
      "CSV Records Loaded: \n",
      "\n",
      "Sample data: \n",
      "            name  age         city  salary\n",
      "0       John Doe   30     New York   75000\n",
      "1     Jane Smith   25  Los Angeles   68000\n",
      "2    Bob Johnson   35      Chicago   82000\n",
      "3    Alice Brown   28      Houston   71000\n",
      "4  Charlie Davis   32      Phoenix   76000\n",
      "\n",
      "Average Salary: 74150.00\n",
      "Processing Time: 0.01 seconds\n",
      "PROCESSING JSON DATA (Semi-Structured)\n",
      "----------------------------------------\n",
      "JSON Records Loaded: \n",
      "\n",
      "Sample data: \n",
      "            name         city  salary  skill_count\n",
      "0       John Doe     New York   75000            3\n",
      "1     Jane Smith  Los Angeles   68000            3\n",
      "2    Bob Johnson      Chicago   82000            3\n",
      "3    Alice Brown      Houston   71000            3\n",
      "4  Charlie Davis      Phoenix   76000            3\n",
      "\n",
      "Average Salary: 74400.00\n",
      "Processing Time: 0.00 seconds\n",
      "PROCESSING XML DATA (Semi-Structured)\n",
      "----------------------------------------\n",
      "XML Records Loaded: \n",
      "\n",
      "Sample data: \n",
      "            name         city   salary  skill_count\n",
      "0       John Doe     New York  75000.0            0\n",
      "1     Jane Smith  Los Angeles  68000.0            0\n",
      "2    Bob Johnson      Chicago  82000.0            0\n",
      "3    Alice Brown      Houston  71000.0            0\n",
      "4  Charlie Davis      Phoenix  76000.0            0\n",
      "\n",
      "Average Salary: 74400.00\n",
      "Processing Time: 0.00 seconds\n",
      "PROCESSING TEXT DATA (Unstructured)\n",
      "----------------------------------------\n",
      "Text Analysis Complete\n",
      "Total Words: 240\n",
      "Unique Words: 168\n",
      "Total Sentences: 15\n",
      "Top 5 Words:\n",
      "  and: 12\n",
      "  data: 11\n",
      "  analytics: 7\n",
      "  the: 6\n",
      "  for: 6\n",
      "Processing Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "df_csv, csv_time = process_csv_data()\n",
    "df_json, json_time = process_json_data()\n",
    "df_xml, xml_time = process_xml_data()\n",
    "process_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9d454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
