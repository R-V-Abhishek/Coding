{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1755077502872,
     "user": {
      "displayName": "Lavanya Naik",
      "userId": "15367076971105143333"
     },
     "user_tz": -330
    },
    "id": "ZUz__MfpxVud",
    "outputId": "7f7c1ea0-11ec-4552-a5bf-a727c91a07b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä SMALL DATA ANALYSIS\n",
      "Total orders: 100\n",
      "Average price: ‚Çπ50917\n",
      "\n",
      "Top products:\n",
      "product\n",
      "Oppo       24\n",
      "iPhone     24\n",
      "Samsung    22\n",
      "OnePlus    15\n",
      "Vivo       15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "City-wise orders:\n",
      "customer_city\n",
      "Mumbai       31\n",
      "Chennai      26\n",
      "Bangalore    22\n",
      "Delhi        21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚è±Ô∏è Processing time: 0.011 seconds\n"
     ]
    }
   ],
   "source": [
    "# File: small_data_analysis.py\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Create small e-commerce data (like a local shop)\n",
    "def create_small_dataset():\n",
    "    products = ['iPhone', 'Samsung', 'OnePlus', 'Vivo', 'Oppo']\n",
    "    data = []\n",
    "\n",
    "    for i in range(100):  # Just 100 sales records\n",
    "        data.append({\n",
    "            'order_id': i+1,\n",
    "            'product': random.choice(products),\n",
    "            'price': random.randint(15000, 80000),\n",
    "            'customer_city': random.choice(['Bangalore', 'Mumbai', 'Delhi', 'Chennai']),\n",
    "            'rating': random.randint(1, 5)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create and analyze small dataset\n",
    "print(\"üìä SMALL DATA ANALYSIS\")\n",
    "df_small = create_small_dataset()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Simple analysis\n",
    "print(f\"Total orders: {len(df_small)}\")\n",
    "print(f\"Average price: ‚Çπ{df_small['price'].mean():.0f}\")\n",
    "print(\"\\nTop products:\")\n",
    "print(df_small['product'].value_counts())\n",
    "print(\"\\nCity-wise orders:\")\n",
    "print(df_small['customer_city'].value_counts())\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n‚è±Ô∏è Processing time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1780,
     "status": "ok",
     "timestamp": 1755077476588,
     "user": {
      "displayName": "Lavanya Naik",
      "userId": "15367076971105143333"
     },
     "user_tz": -330
    },
    "id": "1HFDazVsxL7b",
    "outputId": "24cd0cca-c02c-4e49-b908-dcba6bf198fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Big Data Analytics Lab 1\n",
      "‚úÖ Python version check:\n",
      "‚úÖ Pandas imported successfully!\n",
      "\n",
      "üì± Small Electronics Store Data:\n",
      "   product  price   sold_date\n",
      "0   iPhone  80000  2024-01-01\n",
      "1  Samsung  60000  2024-01-02\n",
      "2  OnePlus  45000  2024-01-01\n",
      "3   iPhone  80000  2024-01-03\n",
      "4  Samsung  65000  2024-01-02\n",
      "Dataset size: 5 records\n"
     ]
    }
   ],
   "source": [
    "# File: lab1_setup.py\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "print(\"‚úÖ Big Data Analytics Lab 1\")\n",
    "print(\"‚úÖ Python version check:\")\n",
    "print(\"‚úÖ Pandas imported successfully!\")\n",
    "\n",
    "# Create a tiny dataset to start\n",
    "small_store = {\n",
    "    'product': ['iPhone', 'Samsung', 'OnePlus', 'iPhone', 'Samsung'],\n",
    "    'price': [80000, 60000, 45000, 80000, 65000],\n",
    "    'sold_date': ['2024-01-01', '2024-01-02', '2024-01-01', '2024-01-03', '2024-01-02']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(small_store)\n",
    "print(\"\\nüì± Small Electronics Store Data:\")\n",
    "print(df)\n",
    "print(f\"Dataset size: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104070,
     "status": "ok",
     "timestamp": 1755077639949,
     "user": {
      "displayName": "Lavanya Naik",
      "userId": "15367076971105143333"
     },
     "user_tz": -330
    },
    "id": "gBaoshzFxd5F",
    "outputId": "58c6a24c-306f-46d4-e22e-3af88675723a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating 1,000 records...\n",
      "\n",
      "üìà ANALYZING 1K Dataset (Small Shop)\n",
      "Total orders: 1,000\n",
      "Average price: ‚Çπ54324\n",
      "Top product: Vivo (159 orders)\n",
      "‚è±Ô∏è Processing time: 0.001 seconds\n",
      "==================================================\n",
      "üîÑ Creating 10,000 records...\n",
      "\n",
      "üìà ANALYZING 10K Dataset (Chain Store)\n",
      "Total orders: 10,000\n",
      "Average price: ‚Çπ52702\n",
      "Top product: OnePlus (1492 orders)\n",
      "‚è±Ô∏è Processing time: 0.002 seconds\n",
      "==================================================\n",
      "üîÑ Creating 50,000 records...\n",
      "\n",
      "üìà ANALYZING 50K Dataset (E-commerce Site)\n",
      "Total orders: 50,000\n",
      "Average price: ‚Çπ52505\n",
      "Top product: OnePlus (7239 orders)\n",
      "‚è±Ô∏è Processing time: 0.002 seconds\n",
      "==================================================\n",
      "üîÑ Creating 100,000 records...\n",
      "\n",
      "üìà ANALYZING 100K Dataset (Big E-commerce)\n",
      "Total orders: 100,000\n",
      "Average price: ‚Çπ52453\n",
      "Top product: Samsung (14410 orders)\n",
      "‚è±Ô∏è Processing time: 0.004 seconds\n",
      "==================================================\n",
      "\n",
      "üìä PERFORMANCE SUMMARY:\n",
      "Dataset Size | Processing Time\n",
      "------------------------------\n",
      "1,000 records | 0.001 seconds\n",
      "10,000 records | 0.002 seconds\n",
      "50,000 records | 0.002 seconds\n",
      "100,000 records | 0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "# File: scaling_challenge.py\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "def create_dataset(size):\n",
    "    \"\"\"Create dataset of given size\"\"\"\n",
    "    products = ['iPhone', 'Samsung', 'OnePlus', 'Vivo', 'Oppo', 'Xiaomi', 'Realme']\n",
    "    cities = ['Bangalore', 'Mumbai', 'Delhi', 'Chennai', 'Pune', 'Hyderabad', 'Kolkata']\n",
    "\n",
    "    data = []\n",
    "    print(f\"üîÑ Creating {size:,} records...\")\n",
    "\n",
    "    for i in range(size):\n",
    "        data.append({\n",
    "            'order_id': i+1,\n",
    "            'product': random.choice(products),\n",
    "            'price': random.randint(5000, 100000),\n",
    "            'customer_city': random.choice(cities),\n",
    "            'rating': random.randint(1, 5),\n",
    "            'order_date': f\"2024-{random.randint(1,12):02d}-{random.randint(1,28):02d}\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def analyze_data(df, dataset_name):\n",
    "    \"\"\"Analyze dataset and measure time\"\"\"\n",
    "    print(f\"\\nüìà ANALYZING {dataset_name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Basic analytics\n",
    "    total_orders = len(df)\n",
    "    avg_price = df['price'].mean()\n",
    "    top_product = df['product'].value_counts().head(1)\n",
    "\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total orders: {total_orders:,}\")\n",
    "    print(f\"Average price: ‚Çπ{avg_price:.0f}\")\n",
    "    print(f\"Top product: {top_product.index[0]} ({top_product.iloc[0]} orders)\")\n",
    "    print(f\"‚è±Ô∏è Processing time: {processing_time:.3f} seconds\")\n",
    "\n",
    "    return processing_time\n",
    "\n",
    "# Progressive challenge\n",
    "datasets = [\n",
    "    (1000, \"1K Dataset (Small Shop)\"),\n",
    "    (10000, \"10K Dataset (Chain Store)\"),\n",
    "    (50000, \"50K Dataset (E-commerce Site)\"),\n",
    "    (100000, \"100K Dataset (Big E-commerce)\")\n",
    "]\n",
    "\n",
    "times = []\n",
    "for size, name in datasets:\n",
    "    df = create_dataset(size)\n",
    "    process_time = analyze_data(df, name)\n",
    "    times.append((size, process_time))\n",
    "\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Ask students to observe\n",
    "    if size == 50000:\n",
    "        input(\"üëÄ Notice the processing time increasing? Press Enter to continue...\")\n",
    "\n",
    "# Show the performance degradation\n",
    "print(\"\\nüìä PERFORMANCE SUMMARY:\")\n",
    "print(\"Dataset Size | Processing Time\")\n",
    "print(\"-\" * 30)\n",
    "for size, ptime in times:\n",
    "    print(f\"{size:,} records | {ptime:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1755077648544,
     "user": {
      "displayName": "Lavanya Naik",
      "userId": "15367076971105143333"
     },
     "user_tz": -330
    },
    "id": "S43eh5v6xnjm",
    "outputId": "8df0cca3-103f-4496-f542-a1b14996b2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç BIG DATA REALITY CHECK\n",
      "========================================\n",
      " Company Daily_Records  Total_Storage\n",
      " Netflix   500 Million   15 Petabytes\n",
      "  Amazon     1 Billion 100+ Petabytes\n",
      "Flipkart   100 Million  10+ Petabytes\n",
      "  Google     8 Billion   15+ Exabytes\n",
      "Facebook     4 Billion 300+ Petabytes\n",
      "\n",
      "ü§Ø SCALE COMPARISON:\n",
      "Your laptop just processed: 100,000 records\n",
      "Netflix processes daily: 500,000,000 records\n",
      "That's 5,000 times more data EVERY DAY!\n",
      "\n",
      "‚ùì QUESTIONS FOR YOU:\n",
      "1. How long would your laptop take to process Netflix's daily data?\n",
      "2. What if Netflix needed results in real-time (seconds)?\n",
      "3. What if your laptop crashes halfway through?\n",
      "\n",
      "üî¢ MATH:\n",
      "Time to process Netflix's daily data on your laptop:\n",
      "500 seconds = 8 minutes = 0.1 hours\n"
     ]
    }
   ],
   "source": [
    "# File: reality_check.py\n",
    "import pandas as pd\n",
    "\n",
    "# Show them the reality\n",
    "print(\"üåç BIG DATA REALITY CHECK\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "real_world_data = {\n",
    "    'Company': ['Netflix', 'Amazon', 'Flipkart', 'Google', 'Facebook'],\n",
    "    'Daily_Records': ['500 Million', '1 Billion', '100 Million', '8 Billion', '4 Billion'],\n",
    "    'Total_Storage': ['15 Petabytes', '100+ Petabytes', '10+ Petabytes', '15+ Exabytes', '300+ Petabytes']\n",
    "}\n",
    "\n",
    "df_reality = pd.DataFrame(real_world_data)\n",
    "print(df_reality.to_string(index=False))\n",
    "\n",
    "print(\"\\nü§Ø SCALE COMPARISON:\")\n",
    "print(\"Your laptop just processed: 100,000 records\")\n",
    "print(\"Netflix processes daily: 500,000,000 records\")\n",
    "print(\"That's 5,000 times more data EVERY DAY!\")\n",
    "\n",
    "print(\"\\n‚ùì QUESTIONS FOR YOU:\")\n",
    "print(\"1. How long would your laptop take to process Netflix's daily data?\")\n",
    "print(\"2. What if Netflix needed results in real-time (seconds)?\")\n",
    "print(\"3. What if your laptop crashes halfway through?\")\n",
    "\n",
    "# Simple calculation\n",
    "your_time_per_100k = 0.1  # Assume 0.1 seconds for 100K records\n",
    "netflix_daily = 500_000_000\n",
    "time_needed = (netflix_daily / 100_000) * your_time_per_100k\n",
    "\n",
    "print(f\"\\nüî¢ MATH:\")\n",
    "print(f\"Time to process Netflix's daily data on your laptop:\")\n",
    "print(f\"{time_needed:.0f} seconds = {time_needed/60:.0f} minutes = {time_needed/3600:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNPml1ODpAlyX+TeU4+fKBg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
